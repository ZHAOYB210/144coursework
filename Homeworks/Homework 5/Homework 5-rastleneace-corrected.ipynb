{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Collaborators: Sarah Neace, sneace@ucsc.edu; Rebekah Astle, rastle@ucsc.edu\n",
      "\n",
      "Credits: Dave Astle "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Problem 1\n",
      "\n",
      "A) For testStr below, write the regular expression `sub` call that replaces all instances of `(sub)` with  `$%\\*$1\\1`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testStr = \"\"\"Down in my sub, I wanted to\n",
      "submit to something (substantial) that wouldn't\n",
      "lead to subalterns calling in{sub}ordination, or anything else\n",
      "that I could (sub).\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "subRE = re.compile(r'\\(sub\\)') #finds (sub)\n",
      "out =  subRE.sub(r'$%\\\\*$1\\\\1', testStr) #replaces (sub) with $%\\*$1\\1\n",
      "print out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Down in my sub, I wanted to\n",
        "submit to something (substantial) that wouldn't\n",
        "lead to subalterns calling in{sub}ordination, or anything else\n",
        "that I could $%\\*$1\\1.\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "B) Now, write another regular expression to substitute `$%\\*$1\\1` with `(sub)`. You'll know you have it right because the output will be identical to `testStr`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "otherFind = re.compile(r'\\$%\\\\\\*\\$1\\\\1') #finds $%\\*$1\\1 with special re characters escaped\n",
      "print otherFind.sub('(sub)', out) == testStr #substitutes $%\\*$1\\1 with (sub) and returns truth value for otherFind.sub == testStr\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Problem 2\n",
      "\n",
      "In this directory, I have provided the file `romanticism.txt`. Please open it and read the entire contents into one string. You can use the `read()` method of the file object to do that. \n",
      "\n",
      "Now the format of the file is like this:\n",
      "\n",
      "line 1: a title line, containing a title and then some citational material and/or other stuff\n",
      "\n",
      "line 2: blank \n",
      "\n",
      "line 3: the url of the resource\n",
      "\n",
      "line 4: blank\n",
      "\n",
      "line 5: like line 1\n",
      "\n",
      "line 6: like line 2\n",
      "\n",
      "etc.\n",
      "\n",
      "Your task here is to use regular expressions to make these into proper HTML links. In html, links use the **anchor** tag, like so:\n",
      "\n",
      "    <a href=\"url\" target=\"BLANK\">link text</a>\n",
      "\n",
      "Please save your output in the string `output`. As you can see in the following line, I'm using that name to display the output as HTML using the `HTML` function from `IPython.display`. You obviously can change this code to your liking. I'm just trying to get things to print in a way that is easy to read. [More here](http://nbviewer.ipython.org/urls/raw.github.com/ipython/ipython/1.x/examples/notebooks/Part%205%20-%20Rich%20Display%20System.ipynb)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "os.chdir(\"/Users/ibersue/Documents/Computational Methods /144coursework/Homeworks/Homework 5\")\n",
      "os.getcwd()\n",
      "\n",
      "rompath = \"./romanticism.txt\" #opens and reads file and assigns it to variable b\n",
      "f = open(rompath, \"r\") \n",
      "b = f.read()\n",
      "\n",
      "\n",
      "\n",
      "fRE = re.compile(r'(?P<title>^\\b[aA-Z0-9].+?(?=[(:,]))(?P<subtitle>:|[(:,].+(?=[:\\n]))\\n\\n(?P<url>^.*$)\\n', re.MULTILINE)\n",
      "#compiles groups for the titles and subtitles (authors,etc.) and URLS in each entry in the file\n",
      "output =  fRE.sub(r'<a href= \\g<url> target= \"BLANK\"> \\g<title> </a>\\g<subtitle><br>', b)\n",
      "#replaces fRE with the title in an html link format (the link being the URL) followed by the subtitle\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "OSError",
       "evalue": "[Errno 2] No such file or directory: '/Users/ibersue/Documents/Computational Methods /144coursework/Homeworks/Homework 5'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-6-104072ecf6b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/ibersue/Documents/Computational Methods /144coursework/Homeworks/Homework 5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrompath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./romanticism.txt\"\u001b[0m \u001b[0;31m#opens and reads file and assigns it to variable b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mOSError\u001b[0m: [Errno 2] No such file or directory: '/Users/ibersue/Documents/Computational Methods /144coursework/Homeworks/Homework 5'"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import HTML\n",
      "HTML(output) #converts output to HTML\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'output' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-7-bd886a14631c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#converts output to HTML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Problem 3\n",
      "\n",
      "The file `ssns.txt` contains a raw text grab of the geneology website [SortedByName](http://sortedbyname.com). You can have a look. Your job in this problem is to convert that raw list of text into a list of dictionaries, of the following sort:\n",
      "\n",
      "    {\"last\": \"Abrams\", \"first\": \"Bobby\", \"born\": \"23 December 1929\", \"died\": \"03 September 2003\", \"ssn\": \"231-28-2235\"}\n",
      "    \n",
      "Note that as someone without a middle name, I don't care to store them."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def skip(line):\n",
      "    \"\"\"this is a series of statements about what kind of lines have junk in them\"\"\"\n",
      "    ignore = re.compile(r'^Here[\\w\\W]+?|^\\s*$') #compiles lines starting with Here and blank lines\n",
      "    if ignore.search(line): #if line matches ignore then skip(true) else don't skip (false)\n",
      "        return 1\n",
      "    else:\n",
      "        return 0 \n",
      "        \n",
      "\n",
      "ssnspath = \".//ssns.txt\"\n",
      "f = open(ssnspath, \"r\") \n",
      "\n",
      "name = re.compile(r'^(?P<first>[a-zA-Z]+),\\s(?P<last>[a-zA-Z]+)')\n",
      "#finds the first and last name by match capital characters ,\\s capital characters\n",
      "born = re.compile(r'(?P<born>(?<=\\bborn\\s)\\d{2}\\s\\w+\\s\\d{4}|ABT \\d{4})') \n",
      "#finds born followed by 2 numbers (the day), a space, word characters, and 4 more numbers (the year) or those beginning with ABT\n",
      "died = re.compile(r'(?P<died>(?<=\\bdied\\s)\\d{2}\\s\\w+\\s\\d{4})')\n",
      "#finds died followed by 2 numbers (the day), a space, word characters, and 4 more numbers (year)\n",
      "ssn = re.compile(r'(?P<ssn>\\d{3}-?\\d{2}-?\\d{4})') \n",
      "#finds 3 digitis followed by a dash followed by 2 more digits, another dash, and then 4 more digits\n",
      "         \n",
      "results = [] #starts a list which will contain dictionaries of people's info\n",
      "for li in f:\n",
      "    if skip(li): #looks for li in skip, skips\n",
      "        continue\n",
      "    newPerson = {} #starts a dictionary for each new person\n",
      "\n",
      "    match = name.search(li)\n",
      "    if match: #it found something\n",
      "        newPerson[\"last\"] = match.groups()[0].capitalize() #adds dict value for last name(1st group) with first letter capitalized \n",
      "        newPerson[\"first\"] = match.groups()[1].capitalize()  #adds dict value for first name(2nd group) with first letter capitalized \n",
      "        \n",
      "    match2 = born.search(li)\n",
      "    if match2: #it found something\n",
      "        newPerson[\"born\"] = match2.groups()[0]  #adds dict value for birth year\n",
      "       \n",
      "    match3 = ssn.search(li)\n",
      "    if match3: #it found something\n",
      "        newPerson[\"ssn\"] = match3.groups()[0] #adds dict value for ssn\n",
      "        \n",
      "    match4 = died.search(li)\n",
      "    if match4: #it found something\n",
      "        newPerson[\"died\"] = match4.groups()[0] #adds dict value for death year\n",
      "        \n",
      "    \n",
      "\n",
      "    results.append(newPerson) # add newPerson to results\n",
      "\n",
      "print results \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[{'born': '23 December 1929', 'ssn': '231-28-2235', 'last': 'Abrams', 'died': '03 September 2003', 'first': 'Bobby'}, {'born': 'ABT 1932', 'last': 'Abrams', 'first': 'Bobby'}, {'born': '20 October 1940', 'ssn': '412-70-1845', 'last': 'Abrams', 'died': '19 February 2011', 'first': 'Bobby'}, {'born': '30 January 1930', 'ssn': '273-28-0459', 'last': 'Abrams', 'died': '02 December 2003', 'first': 'Bobby'}, {'born': '28 August 1931', 'ssn': '448-28-7333', 'last': 'Abrams', 'died': '15 January 2009', 'first': 'Bob'}, {'born': '10 November 1910', 'ssn': '247-10-8958', 'last': 'Abrams', 'first': 'Boisy'}, {'born': '08 September 1954', 'ssn': '187-46-0582', 'last': 'Abrams', 'died': '09 February 2007', 'first': 'Bolden'}, {'born': '21 January 1934', 'ssn': '182-26-7882', 'last': 'Abrams', 'died': '11 March 2008', 'first': 'Bolden'}, {'born': '10 June 1906', 'ssn': '459-46-8859', 'last': 'Abrams', 'first': 'Bonnie'}, {'born': '16 April 1941', 'ssn': '356-34-0421', 'last': 'Abrams', 'died': '13 January 2000', 'first': 'Bonnie'}, {'born': 'ABT 1959', 'last': 'Abrams', 'first': 'Bonnie'}, {'born': '15 May 1891', 'ssn': '065-05-8195', 'last': 'Abrams', 'first': 'Boris'}, {'born': '08 March 1927', 'ssn': '493-32-9021', 'last': 'Abrams', 'died': '22 June 2001', 'first': 'Boris'}, {'born': '26 March 1914', 'ssn': '419-09-7246', 'last': 'Abrams', 'first': 'Bose'}, {'born': 'ABT 1890', 'last': 'Abrams', 'first': 'Bosey'}, {'born': '10 March 1920', 'ssn': '297-05-5931', 'last': 'Abrams', 'died': '22 May 1989', 'first': 'Boyd'}, {'born': '17 January 1903', 'ssn': '317-14-9691', 'last': 'Abrams', 'died': '29 June 1995', 'first': 'Boyd'}, {'born': '23 November 1915', 'ssn': '277-14-8828', 'last': 'Abrams', 'died': '01 April 1991', 'first': 'Boyd'}, {'born': '04 March 1899', 'ssn': '192-28-5193', 'last': 'Abrams', 'first': 'Bradley'}, {'born': 'ABT 1971', 'last': 'Abrams', 'first': 'Brenda'}, {'born': 'ABT 1957', 'last': 'Abrams', 'first': 'Brenda'}, {'born': 'ABT 1957', 'last': 'Abrams', 'first': 'Brenda'}, {'born': '06 May 1947', 'ssn': '102-40-0129', 'last': 'Abrams', 'died': '04 April 2011', 'first': 'Brenda'}, {'born': '31 July 1960', 'ssn': '055-56-2703', 'last': 'Abrams', 'died': '13 May 2006', 'first': 'Brenda'}, {'born': '25 May 1955', 'ssn': '518-70-2249', 'last': 'Abrams', 'died': '13 September 2002', 'first': 'Brent'}, {'born': '31 October 1969', 'ssn': '059-62-0759', 'last': 'Abrams', 'died': '02 June 1989', 'first': 'Brian'}, {'born': 'ABT 1954', 'last': 'Abrams', 'first': 'Brian'}, {'born': '10 June 1964', 'ssn': '118-62-4999', 'last': 'Abrams', 'died': '06 August 2013', 'first': 'Brian'}, {'born': '02 June 1959', 'ssn': '314-72-7401', 'last': 'Abrams', 'died': '20 November 2007', 'first': 'Brian'}, {'born': '16 December 1937', 'ssn': '334-30-0087', 'last': 'Abrams', 'died': '05 March 2008', 'first': 'Brian'}, {'born': '22 April 1956', 'ssn': '329-54-9562', 'last': 'Abrams', 'died': '03 July 2003', 'first': 'Brian'}, {'born': '19 February 1962', 'ssn': '549-11-5463', 'last': 'Abrams', 'died': '05 December 2007', 'first': 'Brian'}, {'born': '02 December 1952', 'ssn': '266-88-5504', 'last': 'Abrams', 'died': '23 November 1997', 'first': 'Brian'}, {'born': '05 October 1908', 'ssn': '064-16-1504', 'last': 'Abrams', 'died': '28 November 2000', 'first': 'Bronny'}, {'born': '19 October 1903', 'ssn': '112-18-8415', 'last': 'Abrams', 'died': '10 December 1999', 'first': 'Broucha'}, {'born': '01 February 1942', 'ssn': '247-70-0202', 'last': 'Abrams', 'first': 'Bruce'}, {'born': '10 April 1938', 'ssn': '403-52-1002', 'last': 'Abrams', 'died': '13 November 2006', 'first': 'Bruce'}, {'born': '11 June 1946', 'ssn': '017-34-5842', 'last': 'Abrams', 'died': '29 January 2010', 'first': 'Bruce'}, {'born': '17 April 1954', 'ssn': '407-84-6662', 'last': 'Abrams', 'died': '14 August 2002', 'first': 'Bruce'}, {'born': '23 June 1950', 'ssn': '125-38-9925', 'last': 'Abrams', 'first': 'Bruce'}, {'last': 'Abrams', 'first': 'Bruce'}, {'born': '20 August 1961', 'ssn': '350-60-8473', 'last': 'Abrams', 'died': '12 December 1999', 'first': 'Bruce'}, {'born': 'ABT 1947', 'last': 'Abrams', 'first': 'Bruce'}, {'born': 'ABT 1947', 'last': 'Abrams', 'first': 'Bruce'}, {'born': 'ABT 1955', 'last': 'Abrams', 'first': 'Bruce'}, {'born': '02 September 1994', 'ssn': '159-76-1092', 'last': 'Abrams', 'died': '26 March 2012', 'first': 'Bryan'}, {'born': '25 January 1918', 'ssn': '571-36-8819', 'last': 'Abrams', 'first': 'Bryce'}, {'born': 'ABT 1939', 'last': 'Abrams', 'first': 'Bud'}, {'last': 'Abrams', 'first': 'Bud'}, {'born': '26 July 1929', 'ssn': '214-26-8819', 'last': 'Abrams', 'died': '09 January 2000', 'first': 'Budell'}, {'born': '30 May 1951', 'ssn': '421-70-3383', 'last': 'Abrams', 'died': '24 August 2007', 'first': 'Bud'}, {'born': '15 November 1910', 'ssn': '225-28-2842', 'last': 'Abrams', 'first': 'Bufer'}, {'last': 'Abrams', 'first': 'Bufus'}, {'born': '01 April 1932', 'ssn': '400-40-1862', 'last': 'Abrams', 'died': '08 April 2013', 'first': 'Burgess'}, {'born': '08 July 1945', 'ssn': '416-66-9028', 'last': 'Abrams', 'first': 'Burke'}, {'born': '10 May 1971', 'ssn': '324-76-9687', 'last': 'Abrams', 'died': '28 March 1995', 'first': 'Burke'}, {'born': '30 October 1911', 'ssn': '400-32-3391', 'last': 'Abrams', 'died': '12 November 2010', 'first': 'Burnace'}, {'born': '17 May 1935', 'ssn': '403-48-4886', 'last': 'Abrams', 'died': '03 November 1996', 'first': 'Burton'}, {'born': '22 July 1926', 'ssn': '288-22-7662', 'last': 'Abrams', 'died': '15 August 1994', 'first': 'Burton'}, {'born': '03 November 1923', 'ssn': '084-14-3261', 'last': 'Abrams', 'died': '23 September 1994', 'first': 'Burton'}, {'born': '19 December 1935', 'ssn': '098-28-4367', 'last': 'Abrams', 'died': '10 November 1995', 'first': 'Burton'}, {'born': '14 September 1893', 'ssn': '422-18-9832', 'last': 'Abrams', 'first': 'Byron'}, {'born': '16 April 1929', 'ssn': '416-34-7145', 'last': 'Abrams', 'died': '27 March 2007', 'first': 'Byron'}, {'born': '02 October 1954', 'ssn': '016-48-3855', 'last': 'Abrams', 'first': 'C'}, {'born': '09 December 1933', 'ssn': '096-26-1173', 'last': 'Abrams', 'died': '15 December 1988', 'first': 'C'}, {'born': '12 July 1910', 'ssn': '523-09-7536', 'last': 'Abrams', 'first': 'C'}, {'born': '13 October 1948', 'ssn': '107-40-1063', 'last': 'Abrams', 'first': 'C'}, {'born': '14 January 1929', 'ssn': '129-38-0800', 'last': 'Abrams', 'first': 'C'}, {'born': '16 March 1900', 'ssn': '290-28-7837', 'last': 'Abrams', 'first': 'C'}, {'born': '22 October 1905', 'ssn': '442-03-2743', 'last': 'Abrams', 'first': 'C'}, {'born': '26 January 1941', 'ssn': '233-64-9421', 'last': 'Abrams', 'died': '15 August 1991', 'first': 'C'}, {'born': '27 March 1882', 'ssn': '558-10-8299', 'last': 'Abrams', 'first': 'C'}, {'born': '25 April 1912', 'ssn': '072-16-8326', 'last': 'Abrams', 'died': '16 March 1995', 'first': 'Calbraith'}, {'born': 'ABT 1859', 'last': 'Abrams', 'first': 'Calista'}, {'born': '01 July 1913', 'ssn': '327-01-8229', 'last': 'Abrams', 'first': 'Calvin'}, {'born': '03 August 1939', 'ssn': '357-32-9977', 'last': 'Abrams', 'died': '16 February 2013', 'first': 'Calvin'}, {'born': '15 January 1927', 'ssn': '204-14-0422', 'last': 'Abrams', 'died': '14 September 2002', 'first': 'Calvin'}, {'born': '02 March 1924', 'ssn': '100-12-2480', 'last': 'Abrams', 'died': '25 February 1997', 'first': 'Calvin'}, {'born': '04 February 1914', 'ssn': '335-01-4627', 'last': 'Abrams', 'died': '31 December 1994', 'first': 'Camille'}, {'born': '08 October 1934', 'ssn': '319-30-5646', 'last': 'Abrams', 'died': '14 February 2011', 'first': 'Candida'}, {'born': 'ABT 1969', 'last': 'Abrams', 'first': 'Candina'}, {'born': 'ABT 1968', 'last': 'Abrams', 'first': 'Candus'}, {'born': '22 February 1914', 'ssn': '263-16-5419', 'last': 'Abrams', 'first': 'Canna'}, {'born': '06 August 1911', 'ssn': '441-36-1249', 'last': 'Abrams', 'died': '19 November 2010', 'first': 'Captiolia'}, {'born': '02 February 1880', 'ssn': '292-10-3526', 'last': 'Abrams', 'first': 'Carl'}, {'born': '03 April 1893', 'ssn': '562-10-5868', 'last': 'Abrams', 'first': 'Carl'}, {'born': '03 June 1914', 'ssn': '063-03-6276', 'last': 'Abrams', 'first': 'Carl'}, {'born': '04 February 1917', 'ssn': '275-16-3319', 'last': 'Abrams', 'first': 'Carl'}, {'born': '04 February 1918', 'ssn': '427-14-1672', 'last': 'Abrams', 'died': '04 April 1985', 'first': 'Carl'}]\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Problem 4\n",
      "\n",
      "Write function `addHTMLTag` so that it wraps every instance of `word` in `string` with tag `tag`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "import re\n",
      "def addHTMLbold(word, string, tag):\n",
      "    \"\"\"this looks for word in string, and wraps all occurrences with tag and end_tag\"\"\"\n",
      "    wordRE = re.compile(r'\\b(?P<word>' + word + r')\\b') #finds only words that match the arg \"word\"\n",
      "    return wordRE.sub('<' + tag + '>\\g<word></' + tag + '>', string) #subs in <tag> and </tag> around the thing in \"word\"\n",
      "\n",
      "mod = addHTMLbold(\"test\", \"This is a test testy to see what testy retests test out\", \"em\")\n",
      "HTML(mod)\n",
      "mod2 = addHTMLbold(\"is\", mod, \"strong\")\n",
      "HTML(mod2)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "This <strong>is</strong> a <em>test</em> testy to see what testy retests <em>test</em> out"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "<IPython.core.display.HTML at 0x102356a90>"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Problem 5\n",
      "\n",
      "A) Write a function `splitWithHTML` that tokenizes a text string on HTML tags, keeping the HTML tags in the tokens"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def splitWithHTML(text):\n",
      "    vs =re.split(r'(<.+?>>\">|<.+?>)', text) #This looks for patterns that match both html tags and the stuff in quotes and then splits inclusively on this. \n",
      "    #this is not a particularly robust or elegant solution seeing as it only accounts for this specific case but we could not\n",
      "    #determine a better solution.\n",
      "    #!!! Seems okay to me. It illustrates the importance of ordering; if you put the more specific pattern second, it fails to match properly\n",
      "    print vs #prints the post split list\n",
      "\n",
      "text = \"\"\"\n",
      "<html>\n",
      "<head><title>This is the title</title>\n",
      "<body onload=\"javascript blah blah>>\">This is what <b>is happening <i> to us</i></b></body>\n",
      "<html>\"\"\"\n",
      "\n",
      "splitWithHTML(text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['\\n', '<html>', '\\n', '<head>', '', '<title>', 'This is the title', '</title>', '\\n', '<body onload=\"javascript blah blah>>\">', 'This is what ', '<b>', 'is happening ', '<i>', ' to us', '</i>', '', '</b>', '', '</body>', '\\n', '<html>', '']\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Problem 6\n",
      "\n",
      "The file `roster.txt` contains the 144 class roster, essentially as a receive it from AIS. Please rewrite each line to show the following elements in the following order: \n",
      "\n",
      "    email address[tab]last name[tab]major1\n",
      "   \n",
      "Note that for the tabs, you should know that the way to find/print them is `\\t`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rosterpath = \".//roster.txt\"\n",
      "f = open(rosterpath, \"r\") #opens roster.txt and reads contents as string\n",
      "\n",
      "#searches for patterns of <td> and </td> which appear before and after every item we want as list item in raw file\n",
      "#is noncapturing so these tags don't get included in the output\n",
      "splitRE = re.compile(r'(?:^\\s*<td>\\s*|\\s*</td>\\s*<td>\\s*|\\s*</td>\\s*$)')\n",
      "#!!! As long as you're capturing more than the three items you need anyway, this one can be accomplished without multiple patterns:\n",
      "#!!! \\s*</?td>\\s* (zero or more spaces on either side of a <td> tag with an optional '/' in it\n",
      "\n",
      "\n",
      "for li in f:\n",
      "    student = re.split(splitRE, li) #splits each line according to the pattern above and assigns the variable student.\n",
      "    print student[9] + '\\t' + student[3] + '\\t' + student[5] #relies on the consistent order of these lists to print each students email, last name and major which are always in these positions\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LINGBA\tRenee\tJimenez\n",
        "LANGBA\tIlona\tKovach\n",
        "PHYSBS\tClaire\tWeiser\n",
        "LINGBA\tAnita\tHuizar\n",
        "LINGBA\tAnthony\tTitone\n",
        "LANGBA\tRae\tRubenking\n",
        "LINGBA\tChristopher\tMata\n",
        "LINGBA\tValentina\tVanegas\n",
        "LINGBA\tMichael\tBuchanan\n",
        "LINGBA\tRebecca\tChan\n",
        "LINGBA\tFrancine\tSanders\n",
        "LINGBA\tMichael\tBianchi\n",
        "LINGBA\tEugene\tWinn\n",
        "LINGBA\t\tErskine\n",
        "LINGBA\tStanley Gordon\tWong\n",
        "LINGBA\tChase\tCorcoran\n",
        "LINGBA\tAnne\tSheets\n",
        "LINGBA\tRandall\tZavala\n",
        "LINGBA\tLabou\tClothier-Goldschmidt\n",
        "PHILBA\tWilliam\tEggert\n",
        "LINGBA\tNicolle\tAstle\n",
        "LINGBA\tAnn\tMiller\n",
        "LINGBA\tRachelle\tNeace\n",
        "LINGBA\tTrevino\tGarcia\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Problem 7\n",
      "\n",
      "I have extracted the first few paragraphs of [the following](http://www.latimes.com/business/la-fi-obamacare-oversold-20131030,0,558878.story#axzz2jBmVwJij) and put it in `healthcare.txt`. Your job is to split this into sentences; I have `healthcare-sentences.txt` as an answer key.\n",
      "\n",
      "For this, you probably want to find the boundaries and then merge them backwards. Another approach is to use a bunch of lookbehind tests. Unfortunately, you can't combine them into one big lookbehind because Python requires lookahead/behind to be constant width patterns. In this case, you'll need two different lookarounds.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#open file and read in contents as one string\n",
      "import os\n",
      "import re\n",
      "healthpath = \".//healthcare.txt\"\n",
      "f = open(healthpath, \"r\")#open file as f\n",
      "c = f.read() #read contents of file as one string\n",
      "\n",
      "sentenceBoundaries = re.compile(r'(\\b[!?.]\"?\\s*)')\n",
      "#makes a group for sentence boundaries - parens around the delimiter (which is a sentence-final punctuation follwed by space(s)\n",
      "theSplit = sentenceBoundaries.split(c)\n",
      "#splits up the file by the sentence boundaries, putting each sentence as an item in a list and its corresponding punct as a separate item\n",
      "\n",
      "theSplit[0::2] #starting at 0, finds every other item in the list\n",
      "theSplit[1::2] #starting at 1, finds every other item in the list\n",
      "\n",
      "healthcareSentences = [(i+j) for i,j in zip(theSplit[::2],theSplit[1::2])]\n",
      "#and then put the sentence boundary back together with the preceding element\n",
      "#zip makes (0,1)(2,3) etc...\n",
      "\n",
      "print \"\\n\".join(healthcareSentences)\n",
      "#!!! Elegant solution.\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "As the pitchman for his landmark healthcare law, President Obama promised to make buying insurance as easy as buying a plane ticket online or a \"TV on Amazon.\" \n",
        "It would be simple, he said. \n",
        "If there were problems, the president predicted, they would be \"glitches.\" \n",
        "And he said, \"If you like the plan you have, you can keep it.\" \n",
        "Such claims have come back to haunt the president and his allies less than a month into the launch of the online insurance marketplaces at the heart of his healthcare legislation. \n",
        "With the federal website hobbled by bad design and thousands of policyholders receiving cancellation notices, Obama's promises are not being met \u2014 prompting charges of deception from some Republicans and concessions from some allies that elements of the law were oversold. \n",
        "The fallout is only the latest chapter in this White House's three-year struggle to sell the public on the Affordable Care Act, which could come to define the president's legacy. \n",
        "Since signing it into law, the president has variously defended it, promoted it, simplified it and hyped it. \n",
        "But polling shows he has never fully sold, nor educated, the public on the vast new government healthcare program. \n",
        "Publicly, the White House continued Tuesday to defend the president's pre-launch salesmanship. \n",
        "\"The purpose here wasn't to do anything beyond encourage people to make themselves aware of the options available to them,\" White House Press Secretary Jay Carney said. \n",
        "Behind closed doors, some officials who worked on the rollout say they wish they'd left themselves a little wiggle room. \n",
        "They could have done more to play up ways to sign up other than through the website, such as the call centers, said one official, requesting anonymity to discuss the planning process. \n",
        "After taking heat from allies for not finding a crisp way to explain the complex law, the White House tried to boil it down to its simplest elements, the official said, and some nuance was inevitably lost. \n",
        "The first administration official to testify before Congress on the matter apologized Tuesday, saying, \"the website has not worked as well as it should.\" \n",
        "\"This initial experience has not lived up to our expectations or the expectations of the American people, and it is not acceptable,\" Marilyn Tavenner, the head of the federal Centers for Medicare and Medicaid Services, told the House Ways and Means Committee. \n",
        "Tavenner's agency oversaw the development of the site, intended to link consumers with affordable private health insurance plans that meet standards outlined in the 2010 law. \n",
        "Tavenner vowed that the site would be running smoothly by the end of November, in time for consumers to enroll before the new year.\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Problem 8\n",
      "\n",
      "find how many times a regular verb is used in a text, organized by tense (To be completed)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}